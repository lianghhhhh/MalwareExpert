# SAFE Model Parameters Documentation

## Overview

The `parameters.py` file defines the `Config` class, which encapsulates all the hyperparameters and configuration settings for the SAFE (Self-Attentive Function Embeddings) model. This class is crucial for maintaining consistency in model architecture and training across different parts of the project.

## Class: Config

```python
class Config:
```

This class defines the configuration parameters for the SAFE model.

### Attributes

- `num_embeddings` (int): The size of the instruction vocabulary. Default: 527683
- `embedding_size` (int): The dimension of the function embedding. Default: 100

#### RNN Parameters
These parameters are specifically used for the RNN model:
- `rnn_state_size` (int): The dimension of the RNN state. Default: 50
- `rnn_depth` (int): The depth (number of layers) of the RNN. Default: 1
- `max_instructions` (int): The maximum number of instructions to consider. Default: 150

#### Attention Parameters
- `attention_hops` (int): The number of attention hops. Default: 10
- `attention_depth` (int): The depth of the attention mechanism. Default: 250

#### Dense Layer Parameter
- `dense_layer_size` (int): The size of the dense layer. Default: 2000

## Usage

To use the `Config` class in your project:

```python
from parameters import Config

# Create a configuration object
config = Config()

# Access configuration parameters
embedding_size = config.embedding_size
rnn_state_size = config.rnn_state_size

# Use in model initialization
model = SAFE(config)
```

## Customization

You can easily customize the configuration by subclassing `Config` or by modifying the values directly after instantiation:

```python
class CustomConfig(Config):
    def __init__(self):
        super().__init__()
        self.embedding_size = 200
        self.rnn_depth = 2

# Or

config = Config()
config.embedding_size = 200
config.rnn_depth = 2
```

This configuration class provides a centralized and easily modifiable way to manage all the hyperparameters of the SAFE model, ensuring consistency and facilitating experimentation with different model architectures.
