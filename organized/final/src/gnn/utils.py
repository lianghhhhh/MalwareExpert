import os
import torch
import logging
import pandas as pd
import networkx as nx
import torch_geometric
import torch_geometric.data
from matplotlib import pyplot as plt
from torch_geometric.explain import Explainer, GNNExplainer, ModelConfig

class MalwareAnalyzer:
    """
    A utility class for malware analysis using graph neural networks.
    """

    def __init__(self, logger=None, config: dict = None):
        """
        Initialize the MalwareAnalyzer.

        Args:
            logger: Logger object. If None, a new logger will be created.
            config (dict, optional): Configuration dictionary.
        """

        if logger is None:
            self.logger = self.set_log()
        else:
            self.logger = logger
        
        self.config = config

    def set_log(self) -> logging.Logger:
        """
        Set up and return a logger for the MalwareAnalyzer.

        Returns:
            logging.Logger: Configured logger object.
        """

        logger = logging.getLogger("MalwareExpert")
        logger.setLevel(logging.INFO)
    
        formatter = logging.Formatter('%(asctime)s - %(filename)s - %(levelname)s - %(message)s')
        file_handler = logging.FileHandler('./log.log', mode='w')
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(formatter)
    
        stream_handler = logging.StreamHandler()
        stream_handler.setFormatter(formatter)
    
        logger.addHandler(file_handler)
        logger.addHandler(stream_handler)
    
        logger.info('Program has started')
        return logger

    # load data
    def load_asm2vec_data(self, embedding_files: list, predict: bool=False):
        """
        Load ASM2Vec data from embedding files.

        Args:
            embedding_files (list): List of embedding file names.
            predict (bool, optional): If True, return data for prediction. Defaults to False.

        Returns:
            tuple: Tuple containing feature matrix, edge index, labels (if not predicting), and file names.
        """

        print('loading data...')
        self.logger.info('loading data...')
        embedding_dir = self.config.folder.vectorize

        feature_matrix = []
        edge_index = []
        name = []

        for file in embedding_files:
            name.append(file)
            file = file + '.dot'
            G = nx.nx_pydot.read_dot(embedding_dir + file)

            # if the node has no embedding, add default embedding 0 array
            for node in G.nodes():
                if "embedding" not in G.nodes[node]:
                    G.nodes[node]["embedding"] = [0]*200
                else:
                    # delete '[' and ']' in the string
                    G.nodes[node]["embedding"] = G.nodes[node]["embedding"].replace('[', '').replace(']', '')
                    # delete '"' in the string
                    G.nodes[node]["embedding"] = G.nodes[node]["embedding"].replace('"', '')

            # get the feature matrix, the order is the same as the adjacency matrix, same as the node index
            # remove \n and \\n
            F = []
            for node in G.nodes():
                # change the string to list of numbers
                if type(G.nodes[node]["embedding"]) == str:
                    embedding = G.nodes[node]["embedding"].replace('\n', '').replace('\\n', '')
                    embedding = list(embedding.split(' '))
                    embedding = list(filter(None, embedding))
                    # change the string to float
                    embedding = [float(i) for i in embedding]
                else:
                    embedding = G.nodes[node]["embedding"]
                F.append(embedding)
            feature_matrix.append(F)

            # get the edge_index
            edge_index0 = []
            edge_index1 = []
            for edge in G.edges():
                # change the node name to index
                edge_index0.append(list(G.nodes).index(edge[0]))
                edge_index1.append(list(G.nodes).index(edge[1]))
            edge_index.append([edge_index0, edge_index1]) #dimension: 2*edge_num

        if predict:
            return feature_matrix, edge_index, name

        # get the label
        label_file = pd.read_csv(self.config.path.label)
        unmap_label = label_file['label']
        filenames = label_file['filename']
            
        label = []
        maps = {'malware': 1, 'benignware': 0}
        unmap_label = unmap_label.map(maps)

        # find filname's index and map the label
        for file in embedding_files:
            index = filenames[filenames == file].index[0] 
            label.append(unmap_label[index])

        return feature_matrix, edge_index, label, name
    
    def load_SAFE_data(self, embedding_files: list, predict: bool=False):
        """
        Load SAFE data from embedding files.

        Args:
            embedding_files (list): List of embedding file names.
            predict (bool, optional): If True, return data for prediction. Defaults to False.

        Returns:
            tuple: Tuple containing feature matrix, edge index, labels (if not predicting), and file names.
        """

        print('loading data...')
        self.logger.info('loading data...')
        embedding_dir = self.config.folder.embedding

        feature_matrix = []
        edge_index = []
        name = []

        for file in embedding_files:
            name.append(file)
            file = file + '.dot'
            G = nx.nx_pydot.read_dot(embedding_dir + file)

            # if the node has no embedding, add default embedding 0 array
            for node in G.nodes():
                if "embedding" not in G.nodes[node]:
                    G.nodes[node]["embedding"] = [0]*100
                else:
                    # delete ""[[" and "]]"" in the string
                    G.nodes[node]["embedding"] = G.nodes[node]["embedding"][3:-3]

            # get the feature matrix, the order is the same as the adjacency matrix, same as the node index
            # remove \n and \\n
            F = []
            for node in G.nodes():
                # change the string to list of numbers
                if type(G.nodes[node]["embedding"]) == str:
                    embedding = G.nodes[node]["embedding"].replace('\n', '').replace('\\n', '')
                    embedding = list(embedding.split(' '))
                    embedding = list(filter(None, embedding))
                    # change the string to float
                    embedding = [float(i) for i in embedding]
                else:
                    embedding = G.nodes[node]["embedding"]
                F.append(embedding)
            feature_matrix.append(F)

            # get the edge_index
            edge_index0 = []
            edge_index1 = []
            for edge in G.edges():
                # change the node name to index
                edge_index0.append(list(G.nodes).index(edge[0]))
                edge_index1.append(list(G.nodes).index(edge[1]))
            edge_index.append([edge_index0, edge_index1]) #dimension: 2*edge_num
        
        if predict:
            return feature_matrix, edge_index, name

        # get the label if not predict
        label_file = pd.read_csv(self.config.path.label)
        unmap_label = label_file['label']
        filenames = label_file['filename']
            
        label = []
        maps = {'malware': 1, 'benignware': 0}
        unmap_label = unmap_label.map(maps)

        # find filname's index and map the label
        for file in embedding_files:
            index = filenames[filenames == file].index[0] 
            label.append(unmap_label[index])

        return feature_matrix, edge_index, label, name

    # train 
    def train(self, model, all_data, criterion, optimizer):
        """
        Train the model for one epoch.

        Args:
            model (torch.nn.Module): The model to train.
            all_data (list): List of training data.
            criterion (torch.nn.Module): Loss function.
            optimizer (torch.optim.Optimizer): Optimizer.

        Returns:
            float: Total loss for the epoch.
        """

        model.train()
        total_loss = 0
        for data in all_data:
            optimizer.zero_grad()
            output = model(data.x, data.edge_index, data)
            loss = criterion(output, data.y)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        return total_loss

    # explain the models
    def GNNexplain(self, model, shard_index: int, slice_index: int, test_data: list):
        """
        Explain the model using GNNExplainer.

        Args:
            model (torch.nn.Module): The model to explain.
            shard_index (int): Index of the shard.
            slice_index (int): Index of the slice.
            test_data (list): List of test data.
        """

        print('GNNexplainer...')
        self.logger.info('GNNexplainer...')
        os.makedirs(self.config.folder.explain, exist_ok=True)
        os.makedirs(self.config.folder.explain + 'GNNexplainer', exist_ok=True)
        os.makedirs(self.config.folder.explain + f'GNNexplainer/model_{shard_index}_{slice_index}', exist_ok=True)
        
        model.eval()

        # use GNNExplainer to explain the model
        explainer = Explainer(
            model=model,
            algorithm=GNNExplainer(epochs=100),
            explanation_type='model',
            node_mask_type='attributes',
            edge_mask_type='object',
            model_config=ModelConfig(
                mode='binary_classification',
                task_level='graph',
                return_type='probs'
            )
        )

        # explanation
        for data in test_data:
            explanation = explainer(
                x=data.x,
                edge_index=data.edge_index,
                data=data
            )
            # print the explanation and visualize the graph
            print(explanation)
            explanation.visualize_graph(path=self.config.folder.explain + f'GNNexplainer/model_{shard_index}_{slice_index}/graph_{data.name}.png')
            # G = explanation.get_explanation_subgraph()
            # print(G)
            # G.visualize_graph(path=self.config.folder.explain + f'GNNexplainer/model_{shard_index}_{slice_index}/subgraph_{data.name}.png')


    # explain the models using graph purning
    # edge prunning, input the graph data, output the pruned graph
    def edge_pruning(self, model, shard_index: int, slice_index: int, test_data: list):
        """
        Perform edge pruning on the graph.

        Args:
            model (torch.nn.Module): The model to use for pruning.
            shard_index (int): Index of the shard.
            slice_index (int): Index of the slice.
            test_data (list): List of test data.
        """
        
        print('edge pruning...')
        self.logger.info('edge pruning...')
        os.makedirs(self.config.folder.explain, exist_ok=True)
        os.makedirs(self.config.folder.explain + 'edge_prune', exist_ok=True)
        os.makedirs(self.config.folder.explain + f'edge_prune/model_{shard_index}_{slice_index}', exist_ok=True)

        for data in test_data:
            # model with original graph
            model.eval()
            with torch.no_grad():
                output = model(data.x, data.edge_index, data) #output is the probability of being benign
                benign_score = output[0][0].item() #get the probability of being benign
            print('benign_score: ', benign_score)
            print('original edge index: ', data.edge_index)

            edge_to_remove = []
            # prune the graph using edge prunning
            for i in range(len(data.edge_index[0])):
                print('i: ', i)
                temp0 = torch.cat((data.edge_index[0][:i], data.edge_index[0][i+1:]))
                temp1 = torch.cat((data.edge_index[1][:i], data.edge_index[1][i+1:]))
                temp_edge_index = torch.stack((temp0, temp1))
                print('temp_edge_index: ', temp_edge_index)

                temp_data = torch_geometric.data.Data(x=data.x, edge_index=temp_edge_index, y=data.y, name=data.name)
                model.eval()
                with torch.no_grad():
                    output = model(temp_data.x, temp_data.edge_index, temp_data)
                    temp_benign_score = output[0][0].item()
                    print('temp_benign_score: ', temp_benign_score)
                    if abs(temp_benign_score - benign_score) < 1e-8: #if the score is not changed much, remove the edge, because the edge is not important
                        edge_to_remove.append(i)

            print('edge to remove: ', edge_to_remove)

            # remove the edge and visualize the pruned graph
            G = nx.Graph()
            for i in range(len(data.edge_index[0])):
                if i not in edge_to_remove:
                    G.add_edge(data.edge_index[0][i].item(), data.edge_index[1][i].item())
            nx.draw(G, with_labels=True)
            plt.show()
            plt.savefig(self.config.folder.explain + f'edge_prune/model_{shard_index}_{slice_index}/{data.name}.png')

            
    # node prunning, input the graph data, output the pruned graph
    def node_pruning(self, model, shard_index: int, slice_index: int, test_data: list):
        """
        Perform node pruning on the graph.

        Args:
            model (torch.nn.Module): The model to use for pruning.
            shard_index (int): Index of the shard.
            slice_index (int): Index of the slice.
            test_data (list): List of test data.
        """
        
        print('node pruning...')
        self.logger.info('node pruning...')
        os.makedirs(self.config.folder.explain, exist_ok=True)
        os.makedirs(self.config.folder.explain + 'node_prune', exist_ok=True)
        os.makedirs(self.config.folder.explain + f'node_prune/model_{shard_index}_{slice_index}', exist_ok=True)

        for data in test_data:
            # model with original graph
            model.eval()
            with torch.no_grad():
                output = model(data.x, data.edge_index, data)
                benign_score = output[0][0].item()
            print('benign_score: ', benign_score)
            print('original x: ', data.x)
            print('original edge index: ', data.edge_index)

            node_to_remove = []
            # prune the graph using node prunning, remove node and its edges
            for i in range(len(data.x)):
                print('i: ', i)
                temp_x = data.x.clone().detach()
                temp_x = torch.cat((temp_x[:i], temp_x[i+1:]))
                print('temp_x: ', temp_x)

                # remove the edges that connect to the removed node
                temp0 = []
                temp1 = []
                for j in range(len(data.edge_index[0])):
                    if data.edge_index[0][j] != i and data.edge_index[1][j] != i:
                        temp0.append(data.edge_index[0][j] if data.edge_index[0][j] < i else data.edge_index[0][j]-1)
                        temp1.append(data.edge_index[1][j] if data.edge_index[1][j] < i else data.edge_index[1][j]-1)
                temp0 = torch.tensor(temp0, dtype=torch.long)
                temp1 = torch.tensor(temp1, dtype=torch.long)
                temp_edge_index = torch.stack((temp0, temp1))
                print('temp_edge_index: ', temp_edge_index)

                temp_data = torch_geometric.data.Data(x=temp_x, edge_index=temp_edge_index, y=data.y, name=data.name)
                model.eval()
                with torch.no_grad():
                    output = model(temp_data.x, temp_data.edge_index, temp_data)
                    temp_benign_score = output[0][0].item()
                    print('temp_benign_score: ', temp_benign_score)
                    if abs(temp_benign_score - benign_score) < 1e-8: #if the score is not changed much, remove the node, because the node is not important
                        node_to_remove.append(i)

            # remove the node and its edges and visualize the pruned graph
            G = nx.Graph()
            for i in range(len(data.edge_index[0])):
                if data.edge_index[0][i] not in node_to_remove and data.edge_index[1][i] not in node_to_remove:
                    G.add_edge(data.edge_index[0][i].item(), data.edge_index[1][i].item())
            nx.draw(G, with_labels=True)
            plt.show()
            plt.savefig(self.config.folder.explain + f'node_prune/model_{shard_index}_{slice_index}/{data.name}.png')
