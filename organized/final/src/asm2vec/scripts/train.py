# Copyright (c) 2021 oalieno

import torch
from ..package import utils

def cli(ipath, opath, mpath, limit, embedding_size=100, batch_size=128, epochs=30, neg_sample_num=25, calc_acc=False, device='auto', lr=0.02):
    if device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    if mpath:
        print("loading model...")
        model, tokens = utils.load_model(mpath, device=device)
        print("loading data...")
        functions, tokens_new, offset = utils.load_data(ipath, limit=limit)
        tokens.update(tokens_new)
        model.update(len(functions), tokens.size())
    else:
        model = None
        print("loading data...")
        functions, tokens, offset = utils.load_data(ipath, limit=limit)
    print("data loaded")

    def callback(context):
        progress = f'{context["epoch"]} | time = {context["time"]:.2f}, loss = {context["loss"]:.4f}'
        if context["accuracy"]:
            progress += f', accuracy = {context["accuracy"]:.4f}'
        print(progress)
        utils.save_model(opath, context["model"], context["tokens"])

    model = utils.train(
        functions,
        tokens,
        model=model,
        embedding_size=embedding_size,
        batch_size=batch_size,
        epochs=epochs,
        neg_sample_num=neg_sample_num,
        calc_acc=calc_acc,
        device=device,
        callback=callback,
        learning_rate=lr
    )

