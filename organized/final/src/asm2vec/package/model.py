# Copyright (c) 2021 oalieno

import torch
import torch.nn as nn

bce, sigmoid, softmax = nn.BCELoss(), nn.Sigmoid(), nn.Softmax(dim=1)

class ASM2VEC(nn.Module):
    """
    ASM2VEC model for learning embeddings of assembly code.
    """
    def __init__(self, vocab_size: int, function_size: int, embedding_size: int):
        """
        Initialize the ASM2VEC model.

        Args:
            vocab_size (int): Size of the token vocabulary.
            function_size (int): Number of unique functions.
            embedding_size (int): Dimension of the embedding vectors.
        """
        super(ASM2VEC, self).__init__()
        self.embeddings   = nn.Embedding(vocab_size, embedding_size, _weight=torch.zeros(vocab_size, embedding_size))
        self.embeddings_f = nn.Embedding(function_size, 2 * embedding_size, _weight=(torch.rand(function_size, 2 * embedding_size)-0.5)/embedding_size/2)
        self.embeddings_r = nn.Embedding(vocab_size, 2 * embedding_size, _weight=(torch.rand(vocab_size, 2 * embedding_size)-0.5)/embedding_size/2)

    def update(self, function_size_new: int, vocab_size_new: int):
        """
        Update the model's embeddings to accommodate new vocabulary or functions.

        Args:
            function_size_new (int): New number of unique functions.
            vocab_size_new (int): New size of the token vocabulary.
        """
        device = self.embeddings.weight.device
        vocab_size, function_size, embedding_size = self.embeddings.num_embeddings, self.embeddings_f.num_embeddings, self.embeddings.embedding_dim
        if vocab_size_new != vocab_size:
            weight = torch.cat([self.embeddings.weight, torch.zeros(vocab_size_new - vocab_size, embedding_size).to(device)])
            self.embeddings = nn.Embedding(vocab_size_new, embedding_size, _weight=weight)
            weight_r = torch.cat([self.embeddings_r.weight, ((torch.rand(vocab_size_new - vocab_size, 2 * embedding_size)-0.5)/embedding_size/2).to(device)])
            self.embeddings_r = nn.Embedding(vocab_size_new, 2 * embedding_size, _weight=weight_r)
        self.embeddings_f = nn.Embedding(function_size_new, 2 * embedding_size, _weight=((torch.rand(function_size_new, 2 * embedding_size)-0.5)/embedding_size/2).to(device))

    def v(self, inp: torch.Tensor) -> torch.Tensor:
        """
        Compute the context vector for a given input sequence.

        Args:
            inp (torch.Tensor): Input tensor containing token indices.

        Returns:
            torch.Tensor: Context vector for the input sequence.
        """
        e  = self.embeddings(inp[:,1:])
        v_f = self.embeddings_f(inp[:,0])
        v_prev = torch.cat([e[:,0], (e[:,1] + e[:,2]) / 2], dim=1)
        v_next = torch.cat([e[:,3], (e[:,4] + e[:,5]) / 2], dim=1)
        v = ((v_f + v_prev + v_next) / 3).unsqueeze(2)
        return v

    def forward(self, inp: torch.Tensor, pos: torch.Tensor, neg: torch.Tensor) -> torch.Tensor:
        """
        Forward pass of the ASM2VEC model.

        Args:
            inp (torch.Tensor): Input tensor containing token indices.
            pos (torch.Tensor): Positive samples for prediction.
            neg (torch.Tensor): Negative samples for prediction.

        Returns:
            torch.Tensor: Binary cross-entropy loss.
        """
        device, batch_size = inp.device, inp.shape[0]
        v = self.v(inp)
        # negative sampling loss
        pred = torch.bmm(self.embeddings_r(torch.cat([pos, neg], dim=1)), v).squeeze() # dim: (batch_size, pos.shape[1] + neg.shape[1])
        label = torch.cat([torch.ones(batch_size, 3), torch.zeros(batch_size, neg.shape[1])], dim=1).to(device) # dim: (batch_size, pos.shape[1] + neg.shape[1])
        
        # if batch_size is 1, pred is a 1D tensor, label is a 2D tensor -> squeeze label
        if pred.dim() == 1:
            label = label.squeeze()

        return bce(sigmoid(pred), label)

    def predict(self, inp: torch.Tensor, pos: torch.Tensor) -> torch.Tensor:
        """
        Predict probabilities for tokens given an input sequence.

        Args:
            inp (torch.Tensor): Input tensor containing token indices.
            pos (torch.Tensor): Positive samples for prediction.

        Returns:
            torch.Tensor: Predicted probabilities for each token in the vocabulary.
        """
        device, batch_size = inp.device, inp.shape[0]
        v = self.v(inp)
        probs = torch.bmm(self.embeddings_r(torch.arange(self.embeddings_r.num_embeddings).repeat(batch_size, 1).to(device)), v).squeeze(dim=2)
        return softmax(probs)
    
    def get_embedding(self, inp: torch.Tensor) -> torch.Tensor:
        """
        Get the embedding of an input function.
        This method computes the average of the embeddings of the tokens in the function.

        Args:
            inp (torch.Tensor): Input tensor containing token indices for a function.

        Returns:
            torch.Tensor: Embedding vector for the input function.
        """
        if(inp.dim() == 1):
            inp = inp.unsqueeze(0)# if the input is a 1D tensor, add a dimension to make it a 2D tensor
        return self.v(inp).mean(dim=0) # dim=0 means average over the batch size dimension -> final dimension is 2*embedding_size
