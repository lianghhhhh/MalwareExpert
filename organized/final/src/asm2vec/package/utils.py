# Copyright (c) 2021 oalieno

import os
import time
import torch
from pathlib import Path
from .model import ASM2VEC
from torch.utils.data import DataLoader, Dataset
from .datatype import Tokens, Function, Instruction

class AsmDataset(Dataset):
    """
    A PyTorch Dataset for assembly code data.
    """
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def __len__(self):
        return len(self.x)
    
    def __getitem__(self, index):
        return self.x[index], self.y[index]

def load_data(paths, limit=None):
    """
    Load assembly code data from specified paths.

    Args:
        paths (str or list): Path(s) to the data files or directories.
        limit (int, optional): Limit on the number of files to load.

    Returns:
        tuple: Contains lists of functions, tokens, and the offset.
    """
    if type(paths) is not list:
        paths = [paths]
        
    dir_names = []
    for path in paths:
        if os.path.isdir(path):
            dir_names += [Path(path) / filename for filename in sorted(os.listdir(path))]
        else:
            dir_names += [Path(path)]
    
    filenames = []
    for dir_name in dir_names:
        if os.path.isdir(dir_name):
            filenames += [Path(dir_name) / filename for filename in sorted(os.listdir(dir_name)) if os.path.isfile(Path(dir_name) / filename)]
        else:
            filenames += [Path(dir_name)]
    #print(filenames)

    functions, tokens = [], Tokens()
    for i, filename in enumerate(filenames):
        if limit and i >= limit:
            break
        with open(filename) as f:
            fn = Function.load(f.read())
            functions.append(fn)
            tokens.add(fn.tokens())
        with open(filename) as f:
            next(f)
            for line in f:
                line = line.strip()
                line = line.split(' ')
                #print(line)
                offset = line[1]
                break
    
    return functions, tokens, offset

def preprocess(functions, tokens):
    """
    Preprocess the loaded functions and tokens.

    Args:
        functions (list): List of Function objects.
        tokens (Tokens): Tokens object containing all tokens.

    Returns:
        tuple: Preprocessed input (x) and target (y) tensors.
    """
    x, y = [], []
    for i, fn in enumerate(functions):
        for seq in fn.random_walk():
            for j in range(1, len(seq) - 1):
                x.append([i] + [tokens[token].index for token in seq[j-1].tokens() + seq[j+1].tokens()])
                y.append([tokens[token].index for token in seq[j].tokens()])
    return torch.tensor(x), torch.tensor(y)

def train(
    functions,
    tokens,
    model=None,
    embedding_size=100,
    batch_size=128,
    epochs=80,
    neg_sample_num=25,
    calc_acc=False,
    device='cpu',
    mode='train',
    callback=None,
    learning_rate=0.02
):
    """
    Train the ASM2VEC model.

    Args:
        functions (list): List of Function objects.
        tokens (Tokens): Tokens object containing all tokens.
        model (ASM2VEC, optional): Pre-trained model for fine-tuning.
        embedding_size (int): Size of the embedding vectors.
        batch_size (int): Batch size for training.
        epochs (int): Number of training epochs.
        neg_sample_num (int): Number of negative samples per positive sample.
        calc_acc (bool): Whether to calculate accuracy during training.
        device (str): Device to use for training ('cpu' or 'cuda').
        mode (str): Training mode ('train' or 'test').
        callback (function, optional): Callback function for logging.
        learning_rate (float): Learning rate for the optimizer.

    Returns:
        ASM2VEC: Trained model.
    """
    if mode == 'train':
        if model is None:
            model = ASM2VEC(tokens.size(), function_size=len(functions), embedding_size=embedding_size).to(device)
        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    elif mode == 'test':
        if model is None:
            raise ValueError("test mode required pretrained model")
        optimizer = torch.optim.Adam(model.embeddings_f.parameters(), lr=learning_rate)
    else:
        raise ValueError("Unknown mode")

    loader = DataLoader(AsmDataset(*preprocess(functions, tokens)), batch_size=batch_size, shuffle=True)
    for epoch in range(epochs):
        start = time.time()
        loss_sum, loss_count, accs = 0.0, 0, []

        model.train()
        for i, (inp, pos) in enumerate(loader):
            neg = tokens.sample(inp.shape[0], neg_sample_num)

            loss = model(inp.to(device), pos.to(device), neg.to(device))
            loss_sum, loss_count = loss_sum + loss, loss_count + 1
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if i == 0 and calc_acc:
                probs = model.predict(inp.to(device), pos.to(device))
                accs.append(accuracy(pos, probs))

        if callback:
            callback({
                'model': model,
                'tokens': tokens,
                'epoch': epoch,
                'time': time.time() - start,
                'loss': loss_sum / loss_count,
                'accuracy': torch.tensor(accs).mean() if calc_acc else None
            })

    return model

def save_model(path, model, tokens):
    """
    Save the trained model and tokens to a file.

    Args:
        path (str): Path to save the model.
        model (ASM2VEC): Trained model to save.
        tokens (Tokens): Tokens object to save.
    """
    torch.save({
        'model_params': (
            model.embeddings.num_embeddings,
            model.embeddings_f.num_embeddings,
            model.embeddings.embedding_dim
        ),
        'model': model.state_dict(),
        'tokens': tokens.state_dict(),
    }, path)

def load_model(path, device='cpu'):
    """
    Load a saved model and tokens from a file.

    Args:
        path (str): Path to the saved model file.
        device (str): Device to load the model onto ('cpu' or 'cuda').

    Returns:
        tuple: Contains the loaded model and tokens.
    """
    checkpoint = torch.load(path, map_location=device)
    tokens = Tokens()
    tokens.load_state_dict(checkpoint['tokens'])
    model = ASM2VEC(*checkpoint['model_params'])
    model.load_state_dict(checkpoint['model'])
    model = model.to(device)
    return model, tokens

def show_probs(x, y, probs, tokens, limit=None, pretty=False):
    """
    Display prediction probabilities for assembly instructions.

    Args:
        x (tensor): Input tensor.
        y (tensor): Target tensor.
        probs (tensor): Prediction probabilities.
        tokens (Tokens): Tokens object for decoding indices.
        limit (int, optional): Limit on the number of samples to display.
        pretty (bool): Whether to use pretty formatting.
    """
    if pretty:
        TL, TR, BL, BR = '┌', '┐', '└', '┘'
        LM, RM, TM, BM = '├', '┤', '┬', '┴'
        H, V = '─', '│'
        arrow = ' ➔'
    else:
        TL = TR = BL = BR = '+'
        LM = RM = TM = BM = '+'
        H, V = '-', '|'
        arrow = '->'
    top = probs.topk(5)
    for i, (xi, yi) in enumerate(zip(x, y)):
        if limit and i >= limit:
            break
        xi, yi = xi.tolist(), yi.tolist()
        print(TL + H * 42 + TR)
        print(f'{V}    {str(Instruction(tokens[xi[1]], tokens[xi[2:4]])):37} {V}')
        print(f'{V} {arrow} {str(Instruction(tokens[yi[0]], tokens[yi[1:3]])):37} {V}')
        print(f'{V}    {str(Instruction(tokens[xi[4]], tokens[xi[5:7]])):37} {V}')
        print(LM + H * 8 + TM + H * 33 + RM)
        for value, index in zip(top.values[i], top.indices[i]):
            if index in yi:
                colorbegin, colorclear = '\033[92m', '\033[0m'
            else:
                colorbegin, colorclear = '', ''
            print(f'{V} {colorbegin}{value*100:05.2f}%{colorclear} {V} {colorbegin}{tokens[index.item()].name:31}{colorclear} {V}')
        print(BL + H * 8 + BM + H * 33 + BR)

def accuracy(y, probs):
    """
    Calculate accuracy of predictions.

    Args:
        y (tensor): Target tensor.
        probs (tensor): Prediction probabilities.

    Returns:
        float: Accuracy score.
    """
    return torch.mean(torch.tensor([torch.sum(probs[i][yi]) for i, yi in enumerate(y)]))

