# for users select data and unlearn it
import torch
import torch_geometric
import torch_geometric.data
from utils import load_shard_data, slice_shard_data, unlearn_data
import csv

#import subDetector from parent directory
import sys
import os
parend_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir))
sys.path.append(parend_dir)
from subDetector import subDetector

# the data to unlearn
data = os.listdir(subDetector().config.folder.unlearn)
for i in range(len(data)):
    data[i] = data[i][:-4] # remove the '.dot' extension

# update the record
with open(subDetector().config.path.record, 'r') as f:
    csv_reader = csv.reader(f)
    next(csv_reader) # skip the header
    record = []
    for row in csv_reader:
        if row[0] in data:
            row[4] = 'True'
        record.append(row)
print('update record...')
with open(subDetector().config.path.record, 'w') as f:
    csv_writer = csv.writer(f)
    csv_writer.writerow(['name', 'shard_index', 'slice_index', 'index_in_slice', 'unlearn'])
    for row in record:
        csv_writer.writerow(row)
print('record updated')

# unlearn the data
for i in range(subDetector().config.model.shard_count):
    print('unlearning shard', i)
    temp_data = [] # store the data to unlearn in this shard
    min_slice = subDetector().config.model.slice_count - 1 # the minimum slice index of the data to unlearn

    with open(subDetector().config.path.record, 'r') as f:
        csv_reader = csv.reader(f)
        next(csv_reader) # skip the header
        for row in csv_reader:
            if row[1] == str(i) and row[4] == 'True': # the data belongs to this shard and need to be unlearned
                temp_data.append(row)
                if int(row[2]) < min_slice:
                    min_slice = int(row[2])
    print('data to unlearn:', temp_data)
    print('min slice:', min_slice)

    # load the whole shard data
    if len(temp_data) > 0:
        shard_feature_matrix, shard_edge_index, shard_label, shard_name = load_shard_data(i)

        # slice the shard data to m parts
        slice_count = subDetector().config.model.slice_count
        slice_feature_matrix, slice_edge_index, slice_label, slice_name = slice_shard_data(shard_feature_matrix, shard_edge_index, shard_label, shard_name, slice_count)
        
        # sort the temp_data by the index in slice(d[3]), descending
        temp_data = sorted(temp_data, key=lambda x: int(x[3]), reverse=True)
        
        # delete the data from the matrix
        for d in temp_data:
            slice_feature_matrix[int(d[2])].remove(slice_feature_matrix[int(d[2])][int(d[3])])
            slice_edge_index[int(d[2])].remove(slice_edge_index[int(d[2])][int(d[3])])
            slice_label[int(d[2])].remove(slice_label[int(d[2])][int(d[3])])
            slice_name[int(d[2])].remove(slice_name[int(d[2])][int(d[3])])
        
        # unlearn the data
        unlearn_data(slice_feature_matrix, slice_edge_index, slice_label, slice_name, i, min_slice, slice_count)
            