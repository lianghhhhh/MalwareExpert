from subDetector import subDetector
import os
import csv
import torch

class SISA():
    def __init__(self)->None:
        super().__init__()
        #initialize n number of subDetectors
        shard_count = subDetector().config.model.shard_count
        slice_count = subDetector().config.model.slice_count
        # create a 2D array of subDetectors, each shard has slice_count subDetectors
        self.myDetector = [[subDetector() for j in range(slice_count)] for i in range(shard_count)]
        for i in range(shard_count):
            for j in range(slice_count):
                self.myDetector[i][j].shard_index = i
                self.myDetector[i][j].slice_index = j
        pass
                

    def preprocess(self):
        #preprocess the data
        for i in range(subDetector().config.model.shard_count):
            for j in range(subDetector().config.model.slice_count):
                detector = self.myDetector[i][j]
                detector.extractFeature(purpose='train')
                detector.vectorize(purpose='train')
        pass

    def divide_data(self):
        print('Dividing data...')

        #split the dataset into training 0.8 and testing 0.2
        dataset_dir = subDetector().config.folder.dataset
        dataset = os.listdir(dataset_dir)
        train_data = dataset[:int(len(dataset)*0.8)]
        test_data = dataset[int(len(dataset)*0.8):]
        shard_count = subDetector().config.model.shard_count
        slice_count = subDetector().config.model.slice_count
        shard_data = []
        slice_data = []

        #shard the train data
        shard_size = len(train_data) // shard_count
        for i in range(shard_count):
            if i == shard_count-1:
                shard_data.append(train_data[i*shard_size:])
            else:
                shard_data.append(train_data[i*shard_size:(i+1)*shard_size])

        #slice the shard data
        slice_size = shard_size // slice_count
        for i in range(shard_count):
            for j in range(slice_count):
                if j == slice_count-1:
                    slice_data.append(shard_data[i][j*slice_size:])
                else:
                    slice_data.append(shard_data[i][j*slice_size:(j+1)*slice_size])

        #write the record
        with open(subDetector().config.path.record, 'w') as f:
            csv_writer = csv.writer(f)
            csv_writer.writerow(['purpose', 'name', 'shard_index', 'slice_index', 'index_in_slice', 'unlearned'])

            # write the train data, and add to subDetector's train_data
            for i in range(shard_count):
                for j in range(slice_count):
                    for k in range(len(slice_data[i*shard_count+j])):
                        csv_writer.writerow(['train', slice_data[i*shard_count+j][k], i, j, k, 'False'])
                        self.myDetector[i][j].train_data.append(slice_data[i*shard_count+j][k])

                # add to subDetector(shard)'s test_data
                self.myDetector[i][0].test_data = test_data
            
            # write the test data
            for i in range(len(test_data)):
                csv_writer.writerow(['test', test_data[i], 'None', 'None', 'None', 'None'])


        pass

    """def shard_data(self):
        #shard data and record
        with open(subDetector().config.path.record, 'r') as f:
            csv_reader = csv.reader(f)
            next(csv_reader) # skip the header
            record = []
            
        pass
    
    def slice_shard_data(self):
        #slice shard data and record
        pass
        
    def load_data(self, i:int, j:int):
        #get data names from the shard(i) and slice(j)
        with open(subDetector().config.path.record, 'r') as f:
            csv_reader = csv.reader(f)
            next(csv_reader)
            for row in csv_reader:
                if row[2] == str(i) and row[3] <= str(j):
                    self.myDetector[i][j].train_data.append(row[1])

        pass"""
        
    def model(self, training:bool=True)->None:
        #model training or prediction
        if training:
            print('sisa training...')

            # create folders for models
            os.makedirs(subDetector().config.folder.model, exist_ok=True)
            os.makedirs(subDetector().config.folder.model + 'slice_models', exist_ok=True)
            os.makedirs(subDetector().config.folder.model + 'shard_models', exist_ok=True)

            # do sisa train here, each slice one subDetector, load and train for a shard
            for i in range(subDetector().config.model.shard_count):
                for j in range(subDetector().config.model.slice_count):
                    #self.load_data(i, j)
                    if j == 0:
                        self.myDetector[i][j].model(training=True)
                    else:
                        # train data = previous train data + current train data
                        self.myDetector[i][j].train_data += self.myDetector[i][j-1].train_data
                        
                        # load the previous slice model, and train the current slice
                        print('need to load model'+f'_{i}_{j-1}')
                        self.myDetector[i][j].model_params = self.myDetector[i][j-1].model(training=False)
                        self.myDetector[i][j].model(training=True)

                    # save the slice model
                    torch.save(self.myDetector[i][j].model_params.state_dict(), subDetector().config.folder.model + f'slice_models/model_{i}_{j}.pt')
                    # save the shard model
                    if j == subDetector().config.model.slice_count-1:
                        torch.save(self.myDetector[i][j].model_params.state_dict(), subDetector().config.folder.model + f'shard_models/model_{i}.pt')

            # after all train finished, do majority vote(testing)
            print('Testing...')
            self.majority_vote(purpose='test')
            
        else:
            print('Load model...')
            # load model for later to predict

    def majority_vote(self, purpose:str='test'):
        # load all shard models and do majority vote
        record = []
        for i in range(subDetector().config.model.shard_count):
            self.myDetector[i][0].extractFeature(purpose=purpose)
            self.myDetector[i][0].vectorize(purpose=purpose)
            record.append(self.myDetector[i][0].predict())

        # do majority vote here
        final_result = []
        for i in range(len(record[0])):
            votes = [0, 0]
            for j in range(subDetector().config.model.shard_count):
                votes[record[j][i]] += 1
            if votes[0] >= votes[1]:
                final_result.append(0)
            else:
                final_result.append(1)

        #if purpose == 'test':
        pass
            
    def machine_unlearning(self):
        #machine unlearning
        for i in range(subDetector().config.model.shard_count):
            for j in range(subDetector().config.model.slice_count):
                myDetector = subDetector()
                myDetector.unlearn_data = self.get_data(i, j)
                myDetector.machine_unlearning()
        pass
