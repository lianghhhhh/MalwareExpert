from subDetector import subDetector
import os
import csv
import torch
import pandas as pd

class SISA():
    def __init__(self)->None:
        shard_count = subDetector().config.model.shard_count
        slice_count = subDetector().config.model.slice_count
        #initialize n number of subDetectors
        # create a 2D array of subDetectors, each shard has slice_count subDetectors
        self.myDetector = [[subDetector() for j in range(slice_count)] for i in range(shard_count)]
        for i in range(shard_count):
            for j in range(slice_count):
                self.myDetector[i][j].shard_index = i
                self.myDetector[i][j].slice_index = j
        pass
                

    def preprocess(self, purpose:str='train'):
        #preprocess the data
        for i in range(subDetector().config.model.shard_count):
            for j in range(subDetector().config.model.slice_count):
                self.myDetector[i][j].extractFeature(purpose=purpose)
                self.myDetector[i][j].vectorize(purpose=purpose)
        pass

    def divide_data(self):
        print('Dividing data...')

        #split the dataset into training 0.8 and testing 0.2
        dataset_dir = subDetector().config.folder.dataset
        dataset = os.listdir(dataset_dir)
        train_data = dataset[:int(len(dataset)*0.8)]
        test_data = dataset[int(len(dataset)*0.8):]
        shard_count = subDetector().config.model.shard_count
        slice_count = subDetector().config.model.slice_count
        shard_data = []
        slice_data = []

        #shard the train data
        shard_size = len(train_data) // shard_count
        for i in range(shard_count):
            if i == shard_count-1:
                shard_data.append(train_data[i*shard_size:])
            else:
                shard_data.append(train_data[i*shard_size:(i+1)*shard_size])

        #slice the shard data
        slice_size = shard_size // slice_count
        for i in range(shard_count):
            for j in range(slice_count):
                if j == slice_count-1:
                    slice_data.append(shard_data[i][j*slice_size:])
                else:
                    slice_data.append(shard_data[i][j*slice_size:(j+1)*slice_size])

        #write the record
        with open(subDetector().config.path.record, 'w') as f:
            csv_writer = csv.writer(f)
            csv_writer.writerow(['purpose', 'name', 'shard_index', 'slice_index', 'index_in_slice', 'unlearned'])

            # write the train data, and add to subDetector's train_data
            for i in range(shard_count):
                for j in range(slice_count):
                    for k in range(len(slice_data[i*shard_count+j])):
                        csv_writer.writerow(['train', slice_data[i*shard_count+j][k], i, j, k, 'False'])
                        self.myDetector[i][j].train_data.append(slice_data[i*shard_count+j][k])

                # add to subDetector(shard)'s test_data
                self.myDetector[i][slice_count-1].test_data = test_data
            
            # write the test data
            for i in range(len(test_data)):
                csv_writer.writerow(['test', test_data[i], 'None', 'None', 'None', 'None'])

        pass
        
    def sisa_training(self)->None:
        #model training
        print('sisa training...')

        # create folders for models
        os.makedirs(subDetector().config.folder.model, exist_ok=True)
        os.makedirs(subDetector().config.folder.model + 'slice_models', exist_ok=True)
        os.makedirs(subDetector().config.folder.model + 'shard_models', exist_ok=True)

        # do sisa train here, each slice one subDetector, load and train for a shard
        for i in range(subDetector().config.model.shard_count):
            for j in range(subDetector().config.model.slice_count):
                if j == 0:
                    self.myDetector[i][j].model(training=True)
                else:
                    # train data = previous train data + current train data
                    self.myDetector[i][j].train_data += self.myDetector[i][j-1].train_data
                    
                    # load the previous slice model, and train the current slice
                    print('need to load model'+f'_{i}_{j-1}')
                    self.myDetector[i][j].model_params = self.myDetector[i][j-1].model(training=False)
                    self.myDetector[i][j].model(training=True)

                # save the slice model
                torch.save(self.myDetector[i][j].model_params.state_dict(), subDetector().config.folder.model + f'slice_models/model_{i}_{j}.pt')
                # save the shard model
                if j == subDetector().config.model.slice_count-1:
                    torch.save(self.myDetector[i][j].model_params.state_dict(), subDetector().config.folder.model + f'shard_models/model_{i}.pt')

        # after all train finished, do majority vote(testing)
        print('Testing...')
        self.majority_vote(purpose='test')
            
    def majority_vote(self, purpose:str='test'):
        last_slice = subDetector().config.model.slice_count - 1
        if purpose == 'predict':
            # get the predict data
            predict_data = os.listdir(subDetector().config.folder.predict)
            for i in range(subDetector().config.model.shard_count):
                self.myDetector[i][last_slice].predict_data = predict_data

        # load all shard models and do majority vote
        record = []
        for i in range(subDetector().config.model.shard_count):
            self.myDetector[i][last_slice].model(training=False) # load the shard model
            self.myDetector[i][last_slice].extractFeature(purpose=purpose)
            self.myDetector[i][last_slice].vectorize(purpose=purpose)
            record.append(self.myDetector[i][last_slice].predict(purpose=purpose))

        # do majority vote here
        final_result = []
        for i in range(len(record[0])):
            votes = [0, 0]
            for j in range(subDetector().config.model.shard_count):
                votes[record[j][i]] += 1
            if votes[0] > votes[1]:
                final_result.append(0)
            else:
                final_result.append(1)

        if purpose == 'test':
            # get labels of the test data
            data = self.myDetector[0][last_slice].test_data
            label_file = pd.read_csv(subDetector().config.path.label)
            unmap_label = label_file['label']
            filenames = label_file['filename']
                
            label = []
            maps = {'malware': 1, 'benignware': 0}
            unmap_label = unmap_label.map(maps)

            #find filname's index and map the label
            for file in data:
                index = filenames[filenames == file].index[0] 
                label.append(unmap_label[index])

            # calculate accuracy
            print('final predict: ', final_result)
            print('label: ', label)
            correct = 0
            for i in range(len(label)):
                if label[i] == final_result[i]:
                    correct += 1
            print('accuracy: ', correct/len(label))
        else:
            with open(subDetector().config.path.predict, 'w') as f:
                csv_writer = csv.writer(f)
                csv_writer.writerow(['filename', 'label'])
                for i in range(len(final_result)):
                    csv_writer.writerow([predict_data[i], final_result[i]])
        pass
            
    def machine_unlearning(self):
        #machine unlearning
        unlearn_data = os.listdir(subDetector().config.folder.unlearn)

        #update the record
        print('update record...')
        with open(subDetector().config.path.record, 'r') as f:
            csv_reader = csv.reader(f)
            next(csv_reader)
            records = list(csv_reader)
            for i in range(1, len(records)):
                if records[i][1] in unlearn_data:
                    records[i][5] = 'True'
        
        with open(subDetector().config.path.record, 'w') as f:
            csv_writer = csv.writer(f)
            csv_writer.writerow(['purpose', 'name', 'shard_index', 'slice_index', 'index_in_slice', 'unlearned'])
            for record in records:
                csv_writer.writerow(record)

        #unlearn the data
        for i in range(subDetector().config.model.shard_count):
            print('unlearning shard: ', i)
            unlearn_data = []
            min_slice = subDetector().config.model.slice_count - 1

            for record in records:
                if record[2] == str(i) and record[5] == 'True':
                    unlearn_data.append(record[1])
                    if int(record[3]) < min_slice:
                        min_slice = int(record[3])
                elif record[2] > str(i):
                    break

            print('min_slice: ', min_slice)
            print('unlearn_data: ', unlearn_data)
            
            #load the slice data to their model train data
            if len(unlearn_data) > 0:
                for j in range(min_slice, subDetector().config.model.slice_count):
                    for record in records:
                        #if is min_slice, need to load the data before min_slice
                        if j == min_slice and record[2] == str(i) and record[3] <= str(j) and record[5] == 'False':
                            self.myDetector[i][j].train_data.append(record[1])
                        elif record[2] == str(i) and record[3] == str(j) and record[5] == 'False':
                            self.myDetector[i][j].train_data.append(record[1])
                        elif record[2] > str(i):
                            break
                
                    if j == 0:
                        print('train a new model')
                        self.myDetector[i][0].model(training=True)
                    else:
                        self.myDetector[i][j].train_data += self.myDetector[i][j-1].train_data
                        print('need to load model'+f'_{i}_{j-1}')
                        self.myDetector[i][j].model_params = self.myDetector[i][j-1].model(training=False)
                        self.myDetector[i][j].model(training=True)

                    #save the slice model
                    torch.save(self.myDetector[i][j].model_params.state_dict(), subDetector().config.folder.model + f'slice_models/model_{i}_{j}.pt')
                    #save the shard model
                    if j == subDetector().config.model.slice_count-1:
                        torch.save(self.myDetector[i][j].model_params.state_dict(), subDetector().config.folder.model + f'shard_models/model_{i}.pt')
        pass

    def explain(self):
        #explain the model
        last_slice = subDetector().config.model.slice_count - 1
        for i in range(subDetector().config.model.shard_count):
                self.myDetector[i][last_slice].model(training=False)
                self.myDetector[i][last_slice].explain()
        pass