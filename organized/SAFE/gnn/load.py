#load a model and train (divide to slices)
import torch
import torch_geometric
import torch_geometric.data
from utils import load_data, slice_shard_data, sisa_train, majority_vote
import csv

#import subDetector from parent directory
import sys
import os
parend_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir))
sys.path.append(parend_dir)
from subDetector import subDetector

#load data
feature_matrix, edge_index, label, name = load_data()

#split to temp(train+val) and test, 0.8 and 0.2
temp_feature_matrix = feature_matrix[:int(len(feature_matrix)*0.8)]
temp_edge_index = edge_index[:int(len(edge_index)*0.8)]
temp_label = label[:int(len(label)*0.8)]
temp_name = name[:int(len(name)*0.8)]
test_feature_matrix = feature_matrix[int(len(feature_matrix)*0.8):]
test_edge_index = edge_index[int(len(edge_index)*0.8):]
test_label = label[int(len(label)*0.8):]
test_name = name[int(len(name)*0.8):]

feature_matrix = temp_feature_matrix
edge_index = temp_edge_index
label = temp_label
name = temp_name

"""#shard the data to n parts
shard_count = subDetector().config.model.shard_count
shard_feature_matrix, shard_edge_index, shard_label, shard_name = shard_data(feature_matrix, edge_index, label, name, shard_count)
print(shard_label)"""

#load the model name
model_name = subDetector().config.path.load_model
model_name = model_name.split('/')[-1] #remove the previous folder path
model_name = model_name[6:-4] #remove 'model_' and '.pth' extension
shard_index = int(model_name.split('_')[0])
print('model name:', model_name)
print('shard index:', shard_index)


#train the model, one model for each shard
#for shard_index in range(shard_count):
#slice the shard data to m parts
slice_count = subDetector().config.model.slice_count
slice_feature_matrix, slice_edge_index, slice_label, slice_name = slice_shard_data(feature_matrix, edge_index, label, name, slice_count)
sisa_train(slice_feature_matrix, slice_edge_index, slice_label, slice_name, shard_index, slice_count, load=True)

# record which shard, slice, and index in slice the data belongs to
with open(subDetector().config.path.record, 'a') as f:
    csv_writer = csv.writer(f)
    for i in range(len(slice_name)):
        for j in range(len(slice_name[i])):
            csv_writer.writerow([slice_name[i][j], shard_index, i, j, 'False'])


#test the models with majority vote
test_x = [torch.tensor(test_feature_matrix[i], dtype=torch.float) for i in range(len(test_feature_matrix))]
test_edge_index = [torch.tensor(test_edge_index[i], dtype=torch.long) for i in range(len(test_edge_index))]
test_y = [torch.tensor(test_label[i], dtype=torch.long) for i in range(len(test_label))]
test_name = test_name
test_data = [torch_geometric.data.Data(x=test_x[i], edge_index=test_edge_index[i], y=test_y[i], name=test_name[i]) for i in range(len(test_x))]

final_predict = []
for data in test_data:
    predict = majority_vote(data)
    final_predict.append(predict)
    print("data name: ", data.name, " label: ", data.y, " predicted: ", predict)

print(final_predict)
print(test_label)
#calculate the accuracy
correct = 0
total = 0
for i in range(len(test_label)):
    if final_predict[i] == test_label[i]:
        correct += 1
    total += 1
print('Accuracy of the network on the test data: %d %%' % (100 * correct / total))
