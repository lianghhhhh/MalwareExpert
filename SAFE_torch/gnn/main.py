import torch
import torch.nn as nn
import torch.optim as optim
import torch_geometric
import torch_geometric.data
from utils import load_data, shard_data, slice_shard_data, sisa_train, majority_vote, unlearn_data, GNNexplain, edge_pruning, node_pruning
import time
import os

#load data
feature_matrix, edge_index, label, name = load_data()

#split to temp(train+val) and test, 0.8 and 0.2
temp_feature_matrix = feature_matrix[:int(len(feature_matrix)*0.8)]
temp_edge_index = edge_index[:int(len(edge_index)*0.8)]
temp_label = label[:int(len(label)*0.8)]
temp_name = name[:int(len(name)*0.8)]
test_feature_matrix = feature_matrix[int(len(feature_matrix)*0.8):]
test_edge_index = edge_index[int(len(edge_index)*0.8):]
test_label = label[int(len(label)*0.8):]
test_name = name[int(len(name)*0.8):]

feature_matrix = temp_feature_matrix
edge_index = temp_edge_index
label = temp_label
name = temp_name

#shard the data to n parts
n=4
shard_feature_matrix, shard_edge_index, shard_label, shard_name = shard_data(feature_matrix, edge_index, label, name, n)
print(shard_label)

#train the model, one model for each shard
for shard_index in range(n):
    #slice the shard data to m parts
    m=2
    slice_feature_matrix, slice_edge_index, slice_label, slice_name = slice_shard_data(shard_feature_matrix[shard_index], shard_edge_index[shard_index], shard_label[shard_index], shard_name[shard_index], m)
    sisa_train(slice_feature_matrix, slice_edge_index, slice_label, slice_name, shard_index, m)

#test the models with majority vote
test_x = [torch.tensor(test_feature_matrix[i], dtype=torch.float) for i in range(len(test_feature_matrix))]
test_edge_index = [torch.tensor(test_edge_index[i], dtype=torch.long) for i in range(len(test_edge_index))]
test_y = [torch.tensor(test_label[i], dtype=torch.long) for i in range(len(test_label))]
test_name = test_name
test_data = [torch_geometric.data.Data(x=test_x[i], edge_index=test_edge_index[i], y=test_y[i], name=test_name[i]) for i in range(len(test_x))]

final_predict = []
for data in test_data:
    predict = majority_vote(data)
    final_predict.append(predict)
    print("data name: ", data.name, " label: ", data.y, " predicted: ", predict)

print(final_predict)
print(test_label)
#calculate the accuracy
correct = 0
total = 0
for i in range(len(test_label)):
    if final_predict[i] == test_label[i]:
        correct += 1
    total += 1
print('Accuracy of the network on the test data: %d %%' % (100 * correct / total))

#unlearn a data
unlearn_data_name = '000a43a528055f8eb373bc1d26dcf0a417d33fcdc5b4cd9326b8e057bba6a785'

#find the index of the data
unlearn_data_index = name.index(unlearn_data_name)
print(unlearn_data_index)

#find the shard index of the data
unlearn_data_shard_index = int(unlearn_data_index / (len(name)/n))
print(unlearn_data_shard_index)

#find the slice index of the data
unlearn_data_slice_index = int(unlearn_data_index / (len(name)/(n*m)) - unlearn_data_shard_index*m)
index_in_slice = int(unlearn_data_index - unlearn_data_shard_index*(len(name)/n) - unlearn_data_slice_index*(len(name)/(n*m)))
print(unlearn_data_slice_index)
print(index_in_slice)

#slice the shard data to m parts
slice_feature_matrix, slice_edge_index, slice_label, slice_name = slice_shard_data(shard_feature_matrix[unlearn_data_shard_index], shard_edge_index[unlearn_data_shard_index], shard_label[unlearn_data_shard_index], shard_name[unlearn_data_shard_index], m)

#unlearn the data
unlearn_data(slice_feature_matrix, slice_edge_index, slice_label, slice_name, unlearn_data_shard_index, unlearn_data_slice_index, index_in_slice, m)

#test the models with majority vote
final_predict = []
for data in test_data:
    predict = majority_vote(data)
    final_predict.append(predict)
    print("data name: ", data.name, " label: ", data.y, " predicted: ", predict)

#calculate the accuracy
correct = 0
total = 0
for i in range(len(test_label)):
    if final_predict[i] == test_label[i]:
        correct += 1
    total += 1
print('Accuracy of the network on the test data: %d %%' % (100 * correct / total))

#explain the model
GNNexplain(test_data)
edge_pruning(test_data)
node_pruning(test_data)

